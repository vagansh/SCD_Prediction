{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c830b583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy.special\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set_context('notebook')\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "##### from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import scipy.stats as st\n",
    "import math\n",
    "\n",
    "seed=45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbaf25ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16809, 18)\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('/Users/ibrain/Downloads/Cognitive Neuroscience Work/Cognition and Lifestyle R Coding/Cognition_Lifestyle/Imbalanced Data/training_set.csv')\n",
    "data=data.iloc[:,1:]\n",
    "data.head()\n",
    "print(data.shape)\n",
    "\n",
    "X = data.drop(columns='CIMEMLOS')\n",
    "Y = data['CIMEMLOS']\n",
    "\n",
    "X_orig=X\n",
    "Y_orig=Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6056775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2401, 18)\n"
     ]
    }
   ],
   "source": [
    "eval_set=pd.read_csv('/Users/ibrain/Downloads/Cognitive Neuroscience Work/Cognition and Lifestyle R Coding/Cognition_Lifestyle/Imbalanced Data/evaluation_set.csv')\n",
    "eval_set=eval_set.iloc[:,1:]\n",
    "eval_set.head()\n",
    "print(eval_set.shape)\n",
    "\n",
    "eval_X = eval_set.drop(columns='CIMEMLOS')\n",
    "eval_Y = eval_set['CIMEMLOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd2d4993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4802, 18)\n"
     ]
    }
   ],
   "source": [
    "test_data=pd.read_csv('/Users/ibrain/Downloads/Cognitive Neuroscience Work/Cognition and Lifestyle R Coding/Cognition_Lifestyle/Imbalanced Data/testing_set.csv')\n",
    "test_data=test_data.iloc[:,1:]\n",
    "test_data.head()\n",
    "print(test_data.shape)\n",
    "\n",
    "test_X = test_data.drop(columns='CIMEMLOS')\n",
    "test_Y = test_data['CIMEMLOS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84874194",
   "metadata": {},
   "source": [
    "## Cluster Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ad75843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 15004, 1: 1805})\n",
      "Resampled dataset shape Counter({0: 12000, 1: 1805})\n"
     ]
    }
   ],
   "source": [
    "# Creating the Dataset from Cluster Centroids method\n",
    "\n",
    "print('Original dataset shape %s' % Counter(Y))\n",
    "cc = ClusterCentroids(estimator=MiniBatchKMeans(n_init=1, random_state=seed), random_state=seed, voting=\"soft\",\n",
    "                     sampling_strategy={0:12000,1:1805})\n",
    "X_res, y_res = cc.fit_resample(X, Y)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57a42183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 12000), (1, 1805)]\n",
      "Cross Validation Results printed....\n",
      "\n",
      "------------------------ Spec ---------------------------\n",
      "\n",
      "Spec Mean= 0.99\n",
      "0.99 [ 0.99 , 0.99 ] 0.0\n",
      "\n",
      "------------------------ Prec ---------------------------\n",
      "\n",
      "Prec Mean= 0.8\n",
      "0.8 [ 0.8 , 0.8 ] 0.02\n",
      "\n",
      "------------------------ Recall ---------------------------\n",
      "\n",
      "Recall Mean= 0.17\n",
      "0.17 [ 0.16 , 0.17 ] 0.01\n",
      "\n",
      "------------------------ F1 ---------------------------\n",
      "\n",
      "F1 Mean= 0.27\n",
      "0.27 [ 0.27 , 0.27 ] 0.02\n",
      "\n",
      "------------------------ BAC ---------------------------\n",
      "\n",
      "BAC Mean= 0.58\n",
      "0.58 [ 0.58 , 0.58 ] 0.01\n",
      "\n",
      "------------------------ AUC ---------------------------\n",
      "\n",
      "AUC Mean= 0.75\n",
      "0.75 [ 0.75 , 0.75 ] 0.01\n",
      "\n",
      "------------------------ TT ---------------------------\n",
      "\n",
      "TT Mean= 2.07\n",
      "2.07 [ 2.07 , 2.07 ] 0.0\n",
      "\n",
      "------------------------ VT ---------------------------\n",
      "\n",
      "VT Mean= 0.07\n",
      "0.07 [ 0.07 , 0.07 ] 0.0\n",
      "\n",
      "\n",
      "Validation Results printed....\n",
      "\n",
      "13805 0    12000\n",
      "1     1805\n",
      "Name: CIMEMLOS, dtype: int64 2401 0    2120\n",
      "1     281\n",
      "Name: CIMEMLOS, dtype: int64\n",
      "[[2112    8]\n",
      " [ 273    8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      2120\n",
      "           1       0.50      0.03      0.05       281\n",
      "\n",
      "    accuracy                           0.88      2401\n",
      "   macro avg       0.69      0.51      0.50      2401\n",
      "weighted avg       0.84      0.88      0.83      2401\n",
      "\n",
      "0.7054774054925133\n"
     ]
    }
   ],
   "source": [
    "#Import library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score ,roc_curve,auc\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "    \n",
    "seed =45\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# choose any method: Bagging Classifier or AdaBoost Classifier\n",
    "\n",
    "# bbc = BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "#                         max_samples=1.0,\n",
    "#                         n_estimators=500,\n",
    "#                         random_state=seed)\n",
    "\n",
    "bbc = AdaBoostClassifier(n_estimators=500,random_state=seed)\n",
    "bbc_original=bbc\n",
    "df=pd.DataFrame(columns = ['Xtr','ytr', 'Spec','Prec', 'Recall', 'F1', 'BAC', 'AUC',\n",
    "                          'TT', 'VT'])\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "X=X_res\n",
    "Y=y_res\n",
    "print(sorted(Counter(y_res).items()))\n",
    "\n",
    "for train_index,test_index in kf.split(X, Y):\n",
    "    #print('{} of KFold {}'.format(i,kf.n_splits))\n",
    "    xtr,xvl = X.iloc[train_index],X.iloc[test_index]\n",
    "    #print(Counter(yvl))\n",
    "    ytr,yvl = Y.iloc[train_index],Y.iloc[test_index]\n",
    "    \n",
    "    start1 = time.time()\n",
    "    bbc.fit(xtr,ytr)\n",
    "    end1=time.time()\n",
    "    \n",
    "    start2 = time.time()\n",
    "    y_pred=bbc.predict(xvl)\n",
    "    end2 = time.time()\n",
    "    \n",
    "    \n",
    "    classification_metrics=classification_report(yvl, y_pred,output_dict=True)\n",
    "    #print(confusion_matrix(yvl,y_pred))\n",
    "    bac=balanced_accuracy_score(yvl, y_pred)\n",
    "    temp_dict=classification_metrics.get('1')\n",
    "\n",
    "    y_pred_proba=bbc.predict_proba(xvl)[::,1]\n",
    "\n",
    "    # Calculation of AUC\n",
    "    auc=metrics.roc_auc_score(yvl, y_pred_proba)\n",
    "    \n",
    "    new_row = pd.Series({'Xtr': len(xtr), 'ytr': ytr.value_counts()[1],\n",
    "                         'Spec': classification_metrics.get('0').get('recall'),\n",
    "                         'Prec': temp_dict.get('precision'),\n",
    "                         'Recall': temp_dict.get('recall'),\n",
    "                         'F1': temp_dict.get('f1-score'),\n",
    "                         'BAC': bac, 'AUC': auc,\n",
    "                         'TT': end1 - start1, 'VT': end2 - start2})\n",
    "    df=pd.concat([df, new_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "\n",
    "print(\"Cross Validation Results printed....\")\n",
    "\n",
    "mean_eval_array=[]\n",
    "\n",
    "for name in df.columns[2:]:\n",
    "    print('\\n------------------------',name,'---------------------------\\n')\n",
    "    #plt.hist(df[name])\n",
    "    #plt.show()\n",
    "\n",
    "    print(name, \"Mean=\" , round(df[name].mean(),2))\n",
    "\n",
    "    t=st.t.interval(df=len(df)-1,alpha=0.05,\n",
    "              loc=np.mean(df[name]),\n",
    "              scale=st.sem(df[name]))\n",
    "\n",
    "\n",
    "    print( round(df[name].mean(),2), \"[\", round(t[0],2),',', round(t[1],2),\"]\", round(st.sem(df[name]),2))\n",
    "    mean_eval_array.append(round(df[name].mean(),2))\n",
    "    \n",
    "\n",
    "# Using the model on the validation set\n",
    "\n",
    "print(\"\\n\\nValidation Results printed....\\n\")\n",
    "print(len(X_res), y_res.value_counts(), len(eval_X), eval_Y.value_counts())\n",
    "\n",
    "bbc = bbc_original\n",
    "bbc.fit(X_res, y_res)\n",
    "y_pred=bbc.predict(eval_X)\n",
    "\n",
    "print(confusion_matrix(eval_Y, y_pred))\n",
    "print(classification_report(eval_Y, y_pred))\n",
    "y_pred_proba=bbc.predict_proba(eval_X)[::,1]\n",
    "\n",
    "    # Calculation of AUC\n",
    "auc=metrics.roc_auc_score(eval_Y, y_pred_proba)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6945e5",
   "metadata": {},
   "source": [
    "## Combine Training and Evaluation Set for Complete Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2e0758c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19210\n",
      "0    17124\n",
      "1     2086\n",
      "Name: CIMEMLOS, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_eval=[data, eval_set]\n",
    "complete_train=pd.concat(train_eval)\n",
    "print(len(complete_train))\n",
    "complete_train_X = complete_train.drop(columns='CIMEMLOS')\n",
    "complete_train_Y = complete_train['CIMEMLOS']\n",
    "print(complete_train_Y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a34771",
   "metadata": {},
   "source": [
    "## Apply Cluster Centroids to the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "807d8574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 17124, 1: 2086})\n",
      "Resampled dataset shape Counter({0: 15000, 1: 2086})\n"
     ]
    }
   ],
   "source": [
    "print('Original dataset shape %s' % Counter(complete_train_Y))\n",
    "cc = ClusterCentroids(estimator=MiniBatchKMeans(n_init=1, random_state=seed), random_state=seed, voting=\"soft\",\n",
    "                     sampling_strategy={0:15000,1:complete_train_Y.value_counts()[1]})\n",
    "X_res, y_res = cc.fit_resample(complete_train_X, complete_train_Y)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a88047b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=500, random_state=45)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51554f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4282   15]\n",
      " [ 498    7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      4297\n",
      "           1       0.32      0.01      0.03       505\n",
      "\n",
      "    accuracy                           0.89      4802\n",
      "   macro avg       0.61      0.51      0.49      4802\n",
      "weighted avg       0.84      0.89      0.85      4802\n",
      "\n",
      "0.6906651428466095\n"
     ]
    }
   ],
   "source": [
    "bbc = bbc_original\n",
    "bbc.fit(X_res, y_res)\n",
    "y_pred=bbc.predict(test_X)\n",
    "\n",
    "print(confusion_matrix(test_Y, y_pred))\n",
    "print(classification_report(test_Y, y_pred))\n",
    "y_pred_proba=bbc.predict_proba(test_X)[::,1]\n",
    "\n",
    "# Calculation of AUC\n",
    "auc=metrics.roc_auc_score(test_Y, y_pred_proba)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f8a17e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
