{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b94bff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy.special\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set_context('notebook')\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "##### from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import scipy.stats as st\n",
    "import math\n",
    "\n",
    "seed=45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3122e1b",
   "metadata": {},
   "source": [
    "## Importing Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8062d8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16809, 18)\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('/Users/ibrain/Downloads/Cognitive Neuroscience Work/Cognition and Lifestyle R Coding/Cognition_Lifestyle/Imbalanced Data/training_set.csv')\n",
    "data=data.iloc[:,1:]\n",
    "data.head()\n",
    "print(data.shape)\n",
    "\n",
    "X = data.drop(columns='CIMEMLOS')\n",
    "Y = data['CIMEMLOS']\n",
    "\n",
    "X_orig=X\n",
    "Y_orig=Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b483351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEXVAR</th>\n",
       "      <th>X.AGEG5YR</th>\n",
       "      <th>X.BMI5</th>\n",
       "      <th>EXERANY2</th>\n",
       "      <th>SLEPTIM1</th>\n",
       "      <th>ADDEPEV3</th>\n",
       "      <th>DIABETE4</th>\n",
       "      <th>CVDSTRK3</th>\n",
       "      <th>smok_everyday</th>\n",
       "      <th>smok_somday</th>\n",
       "      <th>smok_no</th>\n",
       "      <th>SES</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>Multi</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>28.29</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>37.97</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>19.84</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>21.11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>20.53</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEXVAR  X.AGEG5YR  X.BMI5  EXERANY2  SLEPTIM1  ADDEPEV3  DIABETE4  \\\n",
       "0       0         10   28.29         1         7         0         1   \n",
       "1       1         11   37.97         0         6         0         1   \n",
       "2       0          9   19.84         1         8         0         0   \n",
       "3       0          7   21.11         0         4         1         1   \n",
       "4       1         11   20.53         0         4         0         0   \n",
       "\n",
       "   CVDSTRK3  smok_everyday  smok_somday  smok_no  SES  White  Black  Hispanic  \\\n",
       "0         0              0            0        1   11      1      0         0   \n",
       "1         0              0            0        1    5      1      0         0   \n",
       "2         0              1            0        0   14      1      0         0   \n",
       "3         0              0            0        1    6      1      0         0   \n",
       "4         0              1            0        0   12      1      0         0   \n",
       "\n",
       "   Multi  Other  \n",
       "0      0      0  \n",
       "1      0      0  \n",
       "2      0      0  \n",
       "3      0      0  \n",
       "4      0      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a442c5b7",
   "metadata": {},
   "source": [
    "## Importing Evaluation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "378d9eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2401, 18)\n"
     ]
    }
   ],
   "source": [
    "eval_set=pd.read_csv('/Users/ibrain/Downloads/Cognitive Neuroscience Work/Cognition and Lifestyle R Coding/Cognition_Lifestyle/Imbalanced Data/evaluation_set.csv')\n",
    "eval_set=eval_set.iloc[:,1:]\n",
    "eval_set.head()\n",
    "print(eval_set.shape)\n",
    "\n",
    "eval_X = eval_set.drop(columns='CIMEMLOS')\n",
    "eval_Y = eval_set['CIMEMLOS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d197767",
   "metadata": {},
   "source": [
    "## Importing the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1358e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4802, 18)\n"
     ]
    }
   ],
   "source": [
    "test_data=pd.read_csv('/Users/ibrain/Downloads/Cognitive Neuroscience Work/Cognition and Lifestyle R Coding/Cognition_Lifestyle/Imbalanced Data/testing_set.csv')\n",
    "test_data=test_data.iloc[:,1:]\n",
    "test_data.head()\n",
    "print(test_data.shape)\n",
    "\n",
    "test_X = test_data.drop(columns='CIMEMLOS')\n",
    "test_Y = test_data['CIMEMLOS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e536176",
   "metadata": {},
   "source": [
    "## Cluster Centroids + ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30d80eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 15004, 1: 1805})\n",
      "Resampled dataset shape Counter({0: 12000, 1: 1805})\n",
      "[(0, 12000), (1, 1805)]\n",
      "[(0, 12000), (1, 12087)]\n"
     ]
    }
   ],
   "source": [
    "## CC\n",
    "print('Original dataset shape %s' % Counter(Y))\n",
    "cc = ClusterCentroids(estimator=MiniBatchKMeans(n_init=1, random_state=seed), random_state=seed, voting=\"soft\",\n",
    "                     sampling_strategy={0:12000,1:1805})\n",
    "X_res, y_res = cc.fit_resample(X, Y)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "\n",
    "#ADASYN on the dataset returned by CC\n",
    "ada = ADASYN(random_state=42)\n",
    "print(sorted(Counter(y_res).items()))\n",
    "X_res, y_res = ada.fit_resample(X_res, y_res)\n",
    "print(sorted(Counter(y_res).items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e44a662f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 12000), (1, 12087)]\n",
      "Cross Validation Results printed....\n",
      "\n",
      "------------------------ Spec ---------------------------\n",
      "\n",
      "Spec Mean= 0.83\n",
      "0.83 [ 0.83 , 0.83 ] 0.0\n",
      "\n",
      "------------------------ Prec ---------------------------\n",
      "\n",
      "Prec Mean= 0.8\n",
      "0.8 [ 0.8 , 0.8 ] 0.0\n",
      "\n",
      "------------------------ Recall ---------------------------\n",
      "\n",
      "Recall Mean= 0.67\n",
      "0.67 [ 0.67 , 0.67 ] 0.0\n",
      "\n",
      "------------------------ F1 ---------------------------\n",
      "\n",
      "F1 Mean= 0.73\n",
      "0.73 [ 0.73 , 0.73 ] 0.0\n",
      "\n",
      "------------------------ BAC ---------------------------\n",
      "\n",
      "BAC Mean= 0.75\n",
      "0.75 [ 0.75 , 0.75 ] 0.0\n",
      "\n",
      "------------------------ AUC ---------------------------\n",
      "\n",
      "AUC Mean= 0.84\n",
      "0.84 [ 0.84 , 0.84 ] 0.0\n",
      "\n",
      "------------------------ TT ---------------------------\n",
      "\n",
      "TT Mean= 3.78\n",
      "3.78 [ 3.78 , 3.78 ] 0.04\n",
      "\n",
      "------------------------ VT ---------------------------\n",
      "\n",
      "VT Mean= 0.1\n",
      "0.1 [ 0.1 , 0.1 ] 0.0\n",
      "\n",
      "\n",
      "Validation Results printed....\n",
      "\n",
      "24087 1    12087\n",
      "0    12000\n",
      "Name: CIMEMLOS, dtype: int64 2401 0    2120\n",
      "1     281\n",
      "Name: CIMEMLOS, dtype: int64\n",
      "[[1793  327]\n",
      " [ 211   70]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87      2120\n",
      "           1       0.18      0.25      0.21       281\n",
      "\n",
      "    accuracy                           0.78      2401\n",
      "   macro avg       0.54      0.55      0.54      2401\n",
      "weighted avg       0.81      0.78      0.79      2401\n",
      "\n",
      "0.5972100987040893\n"
     ]
    }
   ],
   "source": [
    "#Import library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score ,roc_curve,auc\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "    \n",
    "seed =45\n",
    "\n",
    "# two methods are used : BaggingClassifier and Adaboost Classifier. You can choose any by commenting the other.\n",
    "\n",
    "# bbc = BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "#                         max_samples=1.0,\n",
    "#                         n_estimators=500,\n",
    "#                         random_state=seed)\n",
    "\n",
    "bbc = AdaBoostClassifier(n_estimators=500,random_state=seed)\n",
    "bbc_original=bbc\n",
    "df=pd.DataFrame(columns = ['Xtr','ytr', 'Spec','Prec', 'Recall', 'F1', 'BAC', 'AUC',\n",
    "                          'TT', 'VT'])\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "X=X_res\n",
    "Y=y_res\n",
    "print(sorted(Counter(y_res).items()))\n",
    "\n",
    "for train_index,test_index in kf.split(X, Y):\n",
    "    #print('{} of KFold {}'.format(i,kf.n_splits))\n",
    "    xtr,xvl = X.iloc[train_index],X.iloc[test_index]\n",
    "    #print(Counter(yvl))\n",
    "    ytr,yvl = Y.iloc[train_index],Y.iloc[test_index]\n",
    "    \n",
    "    start1 = time.time()\n",
    "    bbc.fit(xtr,ytr)\n",
    "    end1=time.time()\n",
    "    \n",
    "    start2 = time.time()\n",
    "    y_pred=bbc.predict(xvl)\n",
    "    end2 = time.time()\n",
    "    \n",
    "    \n",
    "    classification_metrics=classification_report(yvl, y_pred,output_dict=True)\n",
    "    #print(confusion_matrix(yvl,y_pred))\n",
    "    bac=balanced_accuracy_score(yvl, y_pred)\n",
    "    temp_dict=classification_metrics.get('1')\n",
    "\n",
    "    y_pred_proba=bbc.predict_proba(xvl)[::,1]\n",
    "\n",
    "    # Calculation of AUC\n",
    "    auc=metrics.roc_auc_score(yvl, y_pred_proba)\n",
    "    \n",
    "    new_row = pd.Series({'Xtr': len(xtr), 'ytr': ytr.value_counts()[1],\n",
    "                         'Spec': classification_metrics.get('0').get('recall'),\n",
    "                         'Prec': temp_dict.get('precision'),\n",
    "                         'Recall': temp_dict.get('recall'),\n",
    "                         'F1': temp_dict.get('f1-score'),\n",
    "                         'BAC': bac, 'AUC': auc,\n",
    "                         'TT': end1 - start1, 'VT': end2 - start2})\n",
    "    df=pd.concat([df, new_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "\n",
    "print(\"Cross Validation Results printed....\")\n",
    "\n",
    "mean_eval_array=[]\n",
    "\n",
    "for name in df.columns[2:]:\n",
    "    print('\\n------------------------',name,'---------------------------\\n')\n",
    "    #plt.hist(df[name])\n",
    "    #plt.show()\n",
    "\n",
    "    print(name, \"Mean=\" , round(df[name].mean(),2))\n",
    "\n",
    "    t=st.t.interval(df=len(df)-1,alpha=0.05,\n",
    "              loc=np.mean(df[name]),\n",
    "              scale=st.sem(df[name]))\n",
    "\n",
    "\n",
    "    print( round(df[name].mean(),2), \"[\", round(t[0],2),',', round(t[1],2),\"]\", round(st.sem(df[name]),2))\n",
    "    mean_eval_array.append(round(df[name].mean(),2))\n",
    "    \n",
    "\n",
    "# Using the model on the validation set\n",
    "\n",
    "print(\"\\n\\nValidation Results printed....\\n\")\n",
    "print(len(X_res), y_res.value_counts(), len(eval_X), eval_Y.value_counts())\n",
    "\n",
    "bbc = bbc_original\n",
    "bbc.fit(X_res, y_res)\n",
    "y_pred=bbc.predict(eval_X)\n",
    "\n",
    "print(confusion_matrix(eval_Y, y_pred))\n",
    "print(classification_report(eval_Y, y_pred))\n",
    "y_pred_proba=bbc.predict_proba(eval_X)[::,1]\n",
    "\n",
    "    # Calculation of AUC\n",
    "auc=metrics.roc_auc_score(eval_Y, y_pred_proba)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b029dccf",
   "metadata": {},
   "source": [
    "## Combine Training and Evaluation Set for Complete Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d855930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19210\n",
      "0    17124\n",
      "1     2086\n",
      "Name: CIMEMLOS, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_eval=[data, eval_set]\n",
    "complete_train=pd.concat(train_eval)\n",
    "print(len(complete_train))\n",
    "complete_train_X = complete_train.drop(columns='CIMEMLOS')\n",
    "complete_train_Y = complete_train['CIMEMLOS']\n",
    "print(complete_train_Y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ada02",
   "metadata": {},
   "source": [
    "## Apply CC + ADASYN to the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3342127b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 17124, 1: 2086})\n",
      "Resampled dataset shape Counter({0: 15000, 1: 1805})\n",
      "[(0, 15000), (1, 1805)]\n",
      "[(0, 15000), (1, 15637)]\n"
     ]
    }
   ],
   "source": [
    "##CC\n",
    "print('Original dataset shape %s' % Counter(complete_train_Y))\n",
    "cc = ClusterCentroids(estimator=MiniBatchKMeans(n_init=1, random_state=seed), random_state=seed, voting=\"soft\",\n",
    "                     sampling_strategy={0:15000,1:1805})\n",
    "X_res, y_res = cc.fit_resample(complete_train_X, complete_train_Y)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "\n",
    "\n",
    "#ADASYN\n",
    "ada = ADASYN(random_state=42)\n",
    "print(sorted(Counter(y_res).items()))\n",
    "X_res, y_res = ada.fit_resample(X_res, y_res)\n",
    "print(sorted(Counter(y_res).items()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad54d92f",
   "metadata": {},
   "source": [
    "## Checking the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "614db3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=500, random_state=45)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "126b5c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3609  688]\n",
      " [ 382  123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87      4297\n",
      "           1       0.15      0.24      0.19       505\n",
      "\n",
      "    accuracy                           0.78      4802\n",
      "   macro avg       0.53      0.54      0.53      4802\n",
      "weighted avg       0.83      0.78      0.80      4802\n",
      "\n",
      "0.5732214738811559\n"
     ]
    }
   ],
   "source": [
    "bbc = bbc_original\n",
    "bbc.fit(X_res, y_res)\n",
    "y_pred=bbc.predict(test_X)\n",
    "\n",
    "print(confusion_matrix(test_Y, y_pred))\n",
    "print(classification_report(test_Y, y_pred))\n",
    "y_pred_proba=bbc.predict_proba(test_X)[::,1]\n",
    "\n",
    "# Calculation of AUC\n",
    "auc=metrics.roc_auc_score(test_Y, y_pred_proba)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed93def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
