{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b94bff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy.special\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set_context('notebook')\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "##### from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import scipy.stats as st\n",
    "import math\n",
    "\n",
    "seed=45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8062d8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16809, 18)\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('/Users/ibrain/Downloads/Cognitive Neuroscience Work/Cognition and Lifestyle R Coding/Cognition_Lifestyle/Imbalanced Data/training_set.csv')\n",
    "data=data.iloc[:,1:]\n",
    "data.head()\n",
    "print(data.shape)\n",
    "\n",
    "X = data.drop(columns='CIMEMLOS')\n",
    "Y = data['CIMEMLOS']\n",
    "\n",
    "X_orig=X\n",
    "Y_orig=Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "378d9eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2401, 18)\n"
     ]
    }
   ],
   "source": [
    "eval_set=pd.read_csv('/Users/ibrain/Downloads/Cognitive Neuroscience Work/Cognition and Lifestyle R Coding/Cognition_Lifestyle/Imbalanced Data/evaluation_set.csv')\n",
    "eval_set=eval_set.iloc[:,1:]\n",
    "eval_set.head()\n",
    "print(eval_set.shape)\n",
    "\n",
    "eval_X = eval_set.drop(columns='CIMEMLOS')\n",
    "eval_Y = eval_set['CIMEMLOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1358e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4802, 18)\n"
     ]
    }
   ],
   "source": [
    "test_data=pd.read_csv('/Users/ibrain/Downloads/Cognitive Neuroscience Work/Cognition and Lifestyle R Coding/Cognition_Lifestyle/Imbalanced Data/testing_set.csv')\n",
    "test_data=test_data.iloc[:,1:]\n",
    "test_data.head()\n",
    "print(test_data.shape)\n",
    "\n",
    "test_X = test_data.drop(columns='CIMEMLOS')\n",
    "test_Y = test_data['CIMEMLOS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889dae50",
   "metadata": {},
   "source": [
    "## Edited Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30d80eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 15004), (1, 1805)]\n",
      "[(0, 11434), (1, 1805)]\n"
     ]
    }
   ],
   "source": [
    "# Creating the resampled data from ENN undersampling method\n",
    "\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours()\n",
    "print(sorted(Counter(Y).items()))\n",
    "X_res, y_res = enn.fit_resample(X, Y)\n",
    "print(sorted(Counter(y_res).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e44a662f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 11434), (1, 1805)]\n",
      "Cross Validation Results printed....\n",
      "\n",
      "------------------------ Spec ---------------------------\n",
      "\n",
      "Spec Mean= 0.98\n",
      "0.98 [ 0.98 , 0.98 ] 0.0\n",
      "\n",
      "------------------------ Prec ---------------------------\n",
      "\n",
      "Prec Mean= 0.56\n",
      "0.56 [ 0.56 , 0.57 ] 0.02\n",
      "\n",
      "------------------------ Recall ---------------------------\n",
      "\n",
      "Recall Mean= 0.15\n",
      "0.15 [ 0.15 , 0.15 ] 0.01\n",
      "\n",
      "------------------------ F1 ---------------------------\n",
      "\n",
      "F1 Mean= 0.24\n",
      "0.24 [ 0.24 , 0.24 ] 0.01\n",
      "\n",
      "------------------------ BAC ---------------------------\n",
      "\n",
      "BAC Mean= 0.57\n",
      "0.57 [ 0.57 , 0.57 ] 0.0\n",
      "\n",
      "------------------------ AUC ---------------------------\n",
      "\n",
      "AUC Mean= 0.76\n",
      "0.76 [ 0.76 , 0.76 ] 0.0\n",
      "\n",
      "------------------------ TT ---------------------------\n",
      "\n",
      "TT Mean= 1.9\n",
      "1.9 [ 1.9 , 1.9 ] 0.0\n",
      "\n",
      "------------------------ VT ---------------------------\n",
      "\n",
      "VT Mean= 0.07\n",
      "0.07 [ 0.07 , 0.07 ] 0.0\n",
      "\n",
      "\n",
      "Validation Results printed....\n",
      "\n",
      "13239 0    11434\n",
      "1     1805\n",
      "Name: CIMEMLOS, dtype: int64 2401 0    2120\n",
      "1     281\n",
      "Name: CIMEMLOS, dtype: int64\n",
      "[[2047   73]\n",
      " [ 241   40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      2120\n",
      "           1       0.35      0.14      0.20       281\n",
      "\n",
      "    accuracy                           0.87      2401\n",
      "   macro avg       0.62      0.55      0.57      2401\n",
      "weighted avg       0.83      0.87      0.84      2401\n",
      "\n",
      "0.7085954810985026\n"
     ]
    }
   ],
   "source": [
    "#Import library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score ,roc_curve,auc\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "    \n",
    "seed =45\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Can use any method : BaggingClassifier or AdaBoostClassifier\n",
    "\n",
    "# bbc = BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "#                         max_samples=1.0,\n",
    "#                         n_estimators=500,\n",
    "#                         random_state=seed)\n",
    "\n",
    "bbc = AdaBoostClassifier(n_estimators=500,random_state=seed)\n",
    "bbc_original=bbc\n",
    "df=pd.DataFrame(columns = ['Xtr','ytr', 'Spec','Prec', 'Recall', 'F1', 'BAC', 'AUC',\n",
    "                          'TT', 'VT'])\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "X=X_res\n",
    "Y=y_res\n",
    "print(sorted(Counter(y_res).items()))\n",
    "\n",
    "for train_index,test_index in kf.split(X, Y):\n",
    "    #print('{} of KFold {}'.format(i,kf.n_splits))\n",
    "    xtr,xvl = X.iloc[train_index],X.iloc[test_index]\n",
    "    #print(Counter(yvl))\n",
    "    ytr,yvl = Y.iloc[train_index],Y.iloc[test_index]\n",
    "    \n",
    "    start1 = time.time()\n",
    "    bbc.fit(xtr,ytr)\n",
    "    end1=time.time()\n",
    "    \n",
    "    start2 = time.time()\n",
    "    y_pred=bbc.predict(xvl)\n",
    "    end2 = time.time()\n",
    "    \n",
    "    \n",
    "    classification_metrics=classification_report(yvl, y_pred,output_dict=True)\n",
    "    #print(confusion_matrix(yvl,y_pred))\n",
    "    bac=balanced_accuracy_score(yvl, y_pred)\n",
    "    temp_dict=classification_metrics.get('1')\n",
    "\n",
    "    y_pred_proba=bbc.predict_proba(xvl)[::,1]\n",
    "\n",
    "    # Calculation of AUC\n",
    "    auc=metrics.roc_auc_score(yvl, y_pred_proba)\n",
    "    \n",
    "    new_row = pd.Series({'Xtr': len(xtr), 'ytr': ytr.value_counts()[1],\n",
    "                         'Spec': classification_metrics.get('0').get('recall'),\n",
    "                         'Prec': temp_dict.get('precision'),\n",
    "                         'Recall': temp_dict.get('recall'),\n",
    "                         'F1': temp_dict.get('f1-score'),\n",
    "                         'BAC': bac, 'AUC': auc,\n",
    "                         'TT': end1 - start1, 'VT': end2 - start2})\n",
    "    df=pd.concat([df, new_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "\n",
    "print(\"Cross Validation Results printed....\")\n",
    "\n",
    "mean_eval_array=[]\n",
    "\n",
    "for name in df.columns[2:]:\n",
    "    print('\\n------------------------',name,'---------------------------\\n')\n",
    "    #plt.hist(df[name])\n",
    "    #plt.show()\n",
    "\n",
    "    print(name, \"Mean=\" , round(df[name].mean(),2))\n",
    "\n",
    "    t=st.t.interval(df=len(df)-1,alpha=0.05,\n",
    "              loc=np.mean(df[name]),\n",
    "              scale=st.sem(df[name]))\n",
    "\n",
    "\n",
    "    print( round(df[name].mean(),2), \"[\", round(t[0],2),',', round(t[1],2),\"]\", round(st.sem(df[name]),2))\n",
    "    mean_eval_array.append(round(df[name].mean(),2))\n",
    "    \n",
    "\n",
    "# Using the model on the validation set\n",
    "\n",
    "print(\"\\n\\nValidation Results printed....\\n\")\n",
    "print(len(X_res), y_res.value_counts(), len(eval_X), eval_Y.value_counts())\n",
    "\n",
    "bbc = bbc_original\n",
    "bbc.fit(X_res, y_res)\n",
    "y_pred=bbc.predict(eval_X)\n",
    "\n",
    "print(confusion_matrix(eval_Y, y_pred))\n",
    "print(classification_report(eval_Y, y_pred))\n",
    "y_pred_proba=bbc.predict_proba(eval_X)[::,1]\n",
    "\n",
    "    # Calculation of AUC\n",
    "auc=metrics.roc_auc_score(eval_Y, y_pred_proba)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b029dccf",
   "metadata": {},
   "source": [
    "## Combine Training and Evaluation Set for Complete Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d855930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19210\n",
      "0    17124\n",
      "1     2086\n",
      "Name: CIMEMLOS, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_eval=[data, eval_set]\n",
    "complete_train=pd.concat(train_eval)\n",
    "print(len(complete_train))\n",
    "complete_train_X = complete_train.drop(columns='CIMEMLOS')\n",
    "complete_train_Y = complete_train['CIMEMLOS']\n",
    "print(complete_train_Y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc87a32",
   "metadata": {},
   "source": [
    "## Apply ENN to the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3342127b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 17124), (1, 2086)]\n",
      "[(0, 13024), (1, 2086)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours()\n",
    "print(sorted(Counter(complete_train_Y).items()))\n",
    "X_res, y_res = enn.fit_resample(complete_train_X, complete_train_Y)\n",
    "print(sorted(Counter(y_res).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad54d92f",
   "metadata": {},
   "source": [
    "## Checking the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "614db3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=500, random_state=45)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "126b5c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4143  154]\n",
      " [ 429   76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93      4297\n",
      "           1       0.33      0.15      0.21       505\n",
      "\n",
      "    accuracy                           0.88      4802\n",
      "   macro avg       0.62      0.56      0.57      4802\n",
      "weighted avg       0.85      0.88      0.86      4802\n",
      "\n",
      "0.7081157243022417\n"
     ]
    }
   ],
   "source": [
    "bbc = bbc_original\n",
    "bbc.fit(X_res, y_res)\n",
    "y_pred=bbc.predict(test_X)\n",
    "\n",
    "print(confusion_matrix(test_Y, y_pred))\n",
    "print(classification_report(test_Y, y_pred))\n",
    "y_pred_proba=bbc.predict_proba(test_X)[::,1]\n",
    "\n",
    "# Calculation of AUC\n",
    "auc=metrics.roc_auc_score(test_Y, y_pred_proba)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed93def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
