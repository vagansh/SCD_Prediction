{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b94bff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy.special\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set_context('notebook')\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "##### from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import scipy.stats as st\n",
    "import math\n",
    "\n",
    "seed=45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8062d8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16809, 18)\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('/Users/ibrain/Downloads/Cognitive Neuroscience Work/Cognition and Lifestyle R Coding/Cognition_Lifestyle/Imbalanced Data/training_set.csv')\n",
    "data=data.iloc[:,1:]\n",
    "data.head()\n",
    "print(data.shape)\n",
    "\n",
    "X = data.drop(columns='CIMEMLOS')\n",
    "Y = data['CIMEMLOS']\n",
    "\n",
    "X_orig=X\n",
    "Y_orig=Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "378d9eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2401, 18)\n"
     ]
    }
   ],
   "source": [
    "eval_set=pd.read_csv('/Users/ibrain/Downloads/Cognitive Neuroscience Work/Cognition and Lifestyle R Coding/Cognition_Lifestyle/Imbalanced Data/evaluation_set.csv')\n",
    "eval_set=eval_set.iloc[:,1:]\n",
    "eval_set.head()\n",
    "print(eval_set.shape)\n",
    "\n",
    "eval_X = eval_set.drop(columns='CIMEMLOS')\n",
    "eval_Y = eval_set['CIMEMLOS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1358e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4802, 18)\n"
     ]
    }
   ],
   "source": [
    "test_data=pd.read_csv('/Users/ibrain/Downloads/Cognitive Neuroscience Work/Cognition and Lifestyle R Coding/Cognition_Lifestyle/Imbalanced Data/testing_set.csv')\n",
    "test_data=test_data.iloc[:,1:]\n",
    "test_data.head()\n",
    "print(test_data.shape)\n",
    "\n",
    "test_X = test_data.drop(columns='CIMEMLOS')\n",
    "test_Y = test_data['CIMEMLOS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fe8e32",
   "metadata": {},
   "source": [
    "## Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30d80eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 15004, 1: 1805})\n",
      "Resampled dataset shape Counter({0: 14377, 1: 1805})\n"
     ]
    }
   ],
   "source": [
    "# Creating new dataset by applying Tomek Links upsampling\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "print('Original dataset shape %s' % Counter(Y))\n",
    "tl = TomekLinks(sampling_strategy=\"majority\")\n",
    "X_res, y_res = tl.fit_resample(X, Y)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e44a662f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 14377), (1, 1805)]\n",
      "Cross Validation Results printed....\n",
      "\n",
      "------------------------ Spec ---------------------------\n",
      "\n",
      "Spec Mean= 0.99\n",
      "0.99 [ 0.99 , 0.99 ] 0.0\n",
      "\n",
      "------------------------ Prec ---------------------------\n",
      "\n",
      "Prec Mean= 0.49\n",
      "0.49 [ 0.49 , 0.5 ] 0.04\n",
      "\n",
      "------------------------ Recall ---------------------------\n",
      "\n",
      "Recall Mean= 0.05\n",
      "0.05 [ 0.05 , 0.05 ] 0.0\n",
      "\n",
      "------------------------ F1 ---------------------------\n",
      "\n",
      "F1 Mean= 0.09\n",
      "0.09 [ 0.09 , 0.09 ] 0.01\n",
      "\n",
      "------------------------ BAC ---------------------------\n",
      "\n",
      "BAC Mean= 0.52\n",
      "0.52 [ 0.52 , 0.52 ] 0.0\n",
      "\n",
      "------------------------ AUC ---------------------------\n",
      "\n",
      "AUC Mean= 0.72\n",
      "0.72 [ 0.72 , 0.72 ] 0.01\n",
      "\n",
      "------------------------ TT ---------------------------\n",
      "\n",
      "TT Mean= 2.31\n",
      "2.31 [ 2.31 , 2.31 ] 0.0\n",
      "\n",
      "------------------------ VT ---------------------------\n",
      "\n",
      "VT Mean= 0.08\n",
      "0.08 [ 0.08 , 0.08 ] 0.0\n",
      "\n",
      "\n",
      "Validation Results printed....\n",
      "\n",
      "16182 0    14377\n",
      "1     1805\n",
      "Name: CIMEMLOS, dtype: int64 2401 0    2120\n",
      "1     281\n",
      "Name: CIMEMLOS, dtype: int64\n",
      "[[2102   18]\n",
      " [ 269   12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      2120\n",
      "           1       0.40      0.04      0.08       281\n",
      "\n",
      "    accuracy                           0.88      2401\n",
      "   macro avg       0.64      0.52      0.51      2401\n",
      "weighted avg       0.83      0.88      0.84      2401\n",
      "\n",
      "0.7081674276505742\n"
     ]
    }
   ],
   "source": [
    "#Import library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score ,roc_curve,auc\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "    \n",
    "seed =45\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# two methods are used : BaggingClassifier and Adaboost Classifier. You can choose any by commenting the other.\n",
    "\n",
    "# bbc = BaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "#                         max_samples=1.0,\n",
    "#                         n_estimators=500,\n",
    "#                         random_state=seed)\n",
    "\n",
    "bbc = AdaBoostClassifier(n_estimators=500,random_state=seed)\n",
    "bbc_original=bbc\n",
    "df=pd.DataFrame(columns = ['Xtr','ytr', 'Spec','Prec', 'Recall', 'F1', 'BAC', 'AUC',\n",
    "                          'TT', 'VT'])\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10,shuffle=True,random_state=seed)\n",
    "X=X_res\n",
    "Y=y_res\n",
    "print(sorted(Counter(y_res).items()))\n",
    "\n",
    "for train_index,test_index in kf.split(X, Y):\n",
    "    #print('{} of KFold {}'.format(i,kf.n_splits))\n",
    "    xtr,xvl = X.iloc[train_index],X.iloc[test_index]\n",
    "    #print(Counter(yvl))\n",
    "    ytr,yvl = Y.iloc[train_index],Y.iloc[test_index]\n",
    "    \n",
    "    start1 = time.time()\n",
    "    bbc.fit(xtr,ytr)\n",
    "    end1=time.time()\n",
    "    \n",
    "    start2 = time.time()\n",
    "    y_pred=bbc.predict(xvl)\n",
    "    end2 = time.time()\n",
    "    \n",
    "    \n",
    "    classification_metrics=classification_report(yvl, y_pred,output_dict=True)\n",
    "    #print(confusion_matrix(yvl,y_pred))\n",
    "    bac=balanced_accuracy_score(yvl, y_pred)\n",
    "    temp_dict=classification_metrics.get('1')\n",
    "\n",
    "    y_pred_proba=bbc.predict_proba(xvl)[::,1]\n",
    "\n",
    "    # Calculation of AUC\n",
    "    auc=metrics.roc_auc_score(yvl, y_pred_proba)\n",
    "    \n",
    "    new_row = pd.Series({'Xtr': len(xtr), 'ytr': ytr.value_counts()[1],\n",
    "                         'Spec': classification_metrics.get('0').get('recall'),\n",
    "                         'Prec': temp_dict.get('precision'),\n",
    "                         'Recall': temp_dict.get('recall'),\n",
    "                         'F1': temp_dict.get('f1-score'),\n",
    "                         'BAC': bac, 'AUC': auc,\n",
    "                         'TT': end1 - start1, 'VT': end2 - start2})\n",
    "    df=pd.concat([df, new_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "\n",
    "print(\"Cross Validation Results printed....\")\n",
    "\n",
    "mean_eval_array=[]\n",
    "\n",
    "for name in df.columns[2:]:\n",
    "    print('\\n------------------------',name,'---------------------------\\n')\n",
    "    #plt.hist(df[name])\n",
    "    #plt.show()\n",
    "\n",
    "    print(name, \"Mean=\" , round(df[name].mean(),2))\n",
    "\n",
    "    t=st.t.interval(df=len(df)-1,alpha=0.05,\n",
    "              loc=np.mean(df[name]),\n",
    "              scale=st.sem(df[name]))\n",
    "\n",
    "\n",
    "    print( round(df[name].mean(),2), \"[\", round(t[0],2),',', round(t[1],2),\"]\", round(st.sem(df[name]),2))\n",
    "    mean_eval_array.append(round(df[name].mean(),2))\n",
    "    \n",
    "\n",
    "# Using the model on the validation set\n",
    "\n",
    "print(\"\\n\\nValidation Results printed....\\n\")\n",
    "print(len(X_res), y_res.value_counts(), len(eval_X), eval_Y.value_counts())\n",
    "\n",
    "bbc = bbc_original\n",
    "bbc.fit(X_res, y_res)\n",
    "y_pred=bbc.predict(eval_X)\n",
    "\n",
    "print(confusion_matrix(eval_Y, y_pred))\n",
    "print(classification_report(eval_Y, y_pred))\n",
    "y_pred_proba=bbc.predict_proba(eval_X)[::,1]\n",
    "\n",
    "    # Calculation of AUC\n",
    "auc=metrics.roc_auc_score(eval_Y, y_pred_proba)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af7374c",
   "metadata": {},
   "source": [
    "## Combine Training and Evaluation Set for Complete Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d855930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19210\n",
      "0    17124\n",
      "1     2086\n",
      "Name: CIMEMLOS, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_eval=[data, eval_set]\n",
    "complete_train=pd.concat(train_eval)\n",
    "print(len(complete_train))\n",
    "complete_train_X = complete_train.drop(columns='CIMEMLOS')\n",
    "complete_train_Y = complete_train['CIMEMLOS']\n",
    "print(complete_train_Y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1e46dc",
   "metadata": {},
   "source": [
    "## Apply Tomek Links to the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3342127b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 17124, 1: 2086})\n",
      "Resampled dataset shape Counter({0: 16398, 1: 2086})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "print('Original dataset shape %s' % Counter(complete_train_Y))\n",
    "tl = TomekLinks(sampling_strategy=\"majority\")\n",
    "X_res, y_res = tl.fit_resample(complete_train_X, complete_train_Y)\n",
    "print('Resampled dataset shape %s' % Counter(y_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a6e935",
   "metadata": {},
   "source": [
    "## Checking the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "614db3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=500, random_state=45)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "126b5c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4261   36]\n",
      " [ 481   24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      4297\n",
      "           1       0.40      0.05      0.08       505\n",
      "\n",
      "    accuracy                           0.89      4802\n",
      "   macro avg       0.65      0.52      0.51      4802\n",
      "weighted avg       0.85      0.89      0.85      4802\n",
      "\n",
      "0.7048454251987917\n"
     ]
    }
   ],
   "source": [
    "bbc = bbc_original\n",
    "bbc.fit(X_res, y_res)\n",
    "y_pred=bbc.predict(test_X)\n",
    "\n",
    "print(confusion_matrix(test_Y, y_pred))\n",
    "print(classification_report(test_Y, y_pred))\n",
    "y_pred_proba=bbc.predict_proba(test_X)[::,1]\n",
    "\n",
    "# Calculation of AUC\n",
    "auc=metrics.roc_auc_score(test_Y, y_pred_proba)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed93def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
